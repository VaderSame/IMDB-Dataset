{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\semal\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\semal\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\semal\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\semal\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\semal\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\semal\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "import numpy as np\n",
    "import re\n",
    "import string \n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a nobl...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a up dated Seahunt series with the tech they have tod...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative idea in the 70's when it first aired. The first 7 o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this film on here I was looking forward to watching th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                review  \\\n",
       "0  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air...   \n",
       "1  Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a nobl...   \n",
       "2  I sure would like to see a resurrection of a up dated Seahunt series with the tech they have tod...   \n",
       "3  This show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 o...   \n",
       "4  Encouraged by the positive comments about this film on here I was looking forward to watching th...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prelim = pd.read_excel(\"IMDB_dataset.xlsx\")\n",
    "imdb_prelim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It had all the clichÃ©s of movies of this type and no substance. The plot went nowhere and at the end of the movie I felt like a sucker for watching it. The production was good; however, the script and acting were B-movie quality. The casting was poor because there were good actors mixed in with crumby actors. The good actors didn't hold their own nor did they lift up the others. <br /><br />This movie is not worthy of more words, but I will say more to meet the minimum requirement of ten lines. James Wood and Cuba Gooding, Jr. play caricatures of themselves in other movies. <br /><br />If you are looking for mindless entertainment, I still wouldn't recommend this movie.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prelim['review'].loc[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>24898</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>When i got this movie free from my job, along with three other similar movies.. I watched then w...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                     review  \\\n",
       "count                                                                                                 25000   \n",
       "unique                                                                                                24898   \n",
       "top     When i got this movie free from my job, along with three other similar movies.. I watched then w...   \n",
       "freq                                                                                                      3   \n",
       "\n",
       "       sentiment  \n",
       "count      25000  \n",
       "unique         2  \n",
       "top     positive  \n",
       "freq       12500  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prelim.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    12500\n",
       "negative    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prelim.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the dataset is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting 'reviews' to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a nobl...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sure would like to see a resurrection of a up dated seahunt series with the tech they have tod...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this show was an amazing, fresh &amp; innovative idea in the 70's when it first aired. the first 7 o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encouraged by the positive comments about this film on here i was looking forward to watching th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                review  \\\n",
       "0  i thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air...   \n",
       "1  probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a nobl...   \n",
       "2  i sure would like to see a resurrection of a up dated seahunt series with the tech they have tod...   \n",
       "3  this show was an amazing, fresh & innovative idea in the 70's when it first aired. the first 7 o...   \n",
       "4  encouraged by the positive comments about this film on here i was looking forward to watching th...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  negative  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prelim['review'] = imdb_prelim['review'].str.lower()\n",
    "imdb_prelim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags (text):\n",
    "    rmv = re.compile('<.*?>')\n",
    "    return rmv.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     i thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air...\n",
       "1     probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a nobl...\n",
       "2     i sure would like to see a resurrection of a up dated seahunt series with the tech they have tod...\n",
       "3     this show was an amazing, fresh & innovative idea in the 70's when it first aired. the first 7 o...\n",
       "4     encouraged by the positive comments about this film on here i was looking forward to watching th...\n",
       "5     phil the alien is one of those quirky films where the humour is based around the oddness of ever...\n",
       "6     i saw this movie when i was about 12 when it came out. i recall the scariest scene was the big b...\n",
       "7     so im not a big fan of boll's work but then again not many are. i enjoyed his movie postal (mayb...\n",
       "8     this a fantastic movie of three prisoners who become famous. one of the actors is george clooney...\n",
       "9     this movie made it into one of my top 10 most awful movies. horrible. there wasn't a continuous ...\n",
       "10    i had the terrible misfortune of having to view this \"b-movie\" in it's entirety.all i have to sa...\n",
       "11    what an absolutely stunning movie, if you have 2.5 hrs to kill, watch it, you won't regret it, i...\n",
       "12    this was the worst movie i saw at worldfest and it also received the least amount of applause af...\n",
       "13    the karen carpenter story shows a little more about singer karen carpenter's complex life. thoug...\n",
       "14    this film tried to be too many things all at once: stinging political satire, hollywood blockbus...\n",
       "15    this movie was so frustrating. everything seemed energetic and i was totally prepared to have a ...\n",
       "16    taut and organically gripping, edward dmytryk's crossfire is a distinctive suspense thriller, an...\n",
       "17    \"ardh satya\" is one of the finest film ever made in indian cinema. directed by the great directo...\n",
       "18    one of the most significant quotes from the entire film is pronounced halfway through by the pro...\n",
       "19    i watched this film not really expecting much, i got it in a pack of 5 films, all of which were ...\n",
       "20    i bought this film at blockbuster for $3.00, because it sounded interesting (a bit ranma-esque, ...\n",
       "21    the plot is about the death of little children. hopper is the one who has to investigate the kil...\n",
       "22    after sitting through this pile of dung, my husband and i wondered whether it was actually the p...\n",
       "23    it had all the clichã©s of movies of this type and no substance. the plot went nowhere and at th...\n",
       "24    this movie is based on the book, \"a many splendored thing\" by han suyin and tackles issues of ra...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prelim['review'] = imdb_prelim['review'].apply(remove_html_tags)\n",
    "imdb_prelim['review'].loc[:24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    re_url = re.compile('https?://\\S+|www\\.\\S+')\n",
    "    return re_url.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a message movie, but a rather good one. outstanding cast, top to bottom. interesting in that bette davis's plot line is essentially back story! the extremely negative reviews (name throwing at the screenplay/playwright, associating this somehow with extremely negative comments about 'angles in america', etc. etc.) object to the movie being too preachy about germany in wwii. gosh, that is just a bit too sophisticated an understanding of morality for me.theatrical and movie-making, and acting styles vary over time and of course 70 years later this particular movie would not be made in this way. yes casablanca is a better movie (i guess), but although made in the same year and both having nazis in them, casablanca is primarily a love story. the love story in this movie takes second seat to the spy plot--more of a thriller. both have a rather large number of somewhat cheesy accents and wonderful character actors. the children are a bit tedious and could have been edited\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prelim['review'] = imdb_prelim['review'].apply(remove_url)\n",
    "imdb_prelim['review'].loc[2336]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    re_punct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return re_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble c...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sure would like to see a resurrection of a up dated seahunt series with the tech they have tod...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this show was an amazing fresh  innovative idea in the 70s when it first aired the first 7 or 8 ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encouraged by the positive comments about this film on here i was looking forward to watching th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                review  \\\n",
       "0  i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air ...   \n",
       "1  probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble c...   \n",
       "2  i sure would like to see a resurrection of a up dated seahunt series with the tech they have tod...   \n",
       "3  this show was an amazing fresh  innovative idea in the 70s when it first aired the first 7 or 8 ...   \n",
       "4  encouraged by the positive comments about this film on here i was looking forward to watching th...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  negative  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prelim['review'] = imdb_prelim['review'].apply(remove_punct)\n",
    "imdb_prelim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to, spend, time, on, a, too, hot, summer, weekend, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[probably, my, alltime, favorite, movie, a, story, of, selflessness, sacrifice, and, dedication,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sure would like to see a resurrection of a up dated seahunt series with the tech they have tod...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, sure, would, like, to, see, a, resurrection, of, a, up, dated, seahunt, series, with, the, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this show was an amazing fresh  innovative idea in the 70s when it first aired the first 7 or 8 ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[this, show, was, an, amazing, fresh, innovative, idea, in, the, 70s, when, it, first, aired, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encouraged by the positive comments about this film on here i was looking forward to watching th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[encouraged, by, the, positive, comments, about, this, film, on, here, i, was, looking, forward,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                review  \\\n",
       "0  i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air ...   \n",
       "1  probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble c...   \n",
       "2  i sure would like to see a resurrection of a up dated seahunt series with the tech they have tod...   \n",
       "3  this show was an amazing fresh  innovative idea in the 70s when it first aired the first 7 or 8 ...   \n",
       "4  encouraged by the positive comments about this film on here i was looking forward to watching th...   \n",
       "\n",
       "  sentiment  \\\n",
       "0  positive   \n",
       "1  positive   \n",
       "2  positive   \n",
       "3  negative   \n",
       "4  negative   \n",
       "\n",
       "                                                                                          review_token  \n",
       "0  [i, thought, this, was, a, wonderful, way, to, spend, time, on, a, too, hot, summer, weekend, si...  \n",
       "1  [probably, my, alltime, favorite, movie, a, story, of, selflessness, sacrifice, and, dedication,...  \n",
       "2  [i, sure, would, like, to, see, a, resurrection, of, a, up, dated, seahunt, series, with, the, t...  \n",
       "3  [this, show, was, an, amazing, fresh, innovative, idea, in, the, 70s, when, it, first, aired, th...  \n",
       "4  [encouraged, by, the, positive, comments, about, this, film, on, here, i, was, looking, forward,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prelim['review_token'] = imdb_prelim['review'].apply(tokenize)\n",
    "imdb_prelim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    re_stp = [word for word in text if word not in stopwords_english]\n",
    "    return re_stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_token</th>\n",
       "      <th>review_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to, spend, time, on, a, too, hot, summer, weekend, si...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, summer, weekend, sitting, air, conditioned, theater,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[probably, my, alltime, favorite, movie, a, story, of, selflessness, sacrifice, and, dedication,...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, selflessness, sacrifice, dedication, noble, cause, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sure would like to see a resurrection of a up dated seahunt series with the tech they have tod...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, sure, would, like, to, see, a, resurrection, of, a, up, dated, seahunt, series, with, the, t...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, seahunt, series, tech, today, would, bring, back, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this show was an amazing fresh  innovative idea in the 70s when it first aired the first 7 or 8 ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[this, show, was, an, amazing, fresh, innovative, idea, in, the, 70s, when, it, first, aired, th...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70s, first, aired, first, 7, 8, years, brilliant, thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encouraged by the positive comments about this film on here i was looking forward to watching th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[encouraged, by, the, positive, comments, about, this, film, on, here, i, was, looking, forward,...</td>\n",
       "      <td>[encouraged, positive, comments, film, looking, forward, watching, film, bad, mistake, ive, seen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                review  \\\n",
       "0  i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air ...   \n",
       "1  probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble c...   \n",
       "2  i sure would like to see a resurrection of a up dated seahunt series with the tech they have tod...   \n",
       "3  this show was an amazing fresh  innovative idea in the 70s when it first aired the first 7 or 8 ...   \n",
       "4  encouraged by the positive comments about this film on here i was looking forward to watching th...   \n",
       "\n",
       "  sentiment  \\\n",
       "0  positive   \n",
       "1  positive   \n",
       "2  positive   \n",
       "3  negative   \n",
       "4  negative   \n",
       "\n",
       "                                                                                          review_token  \\\n",
       "0  [i, thought, this, was, a, wonderful, way, to, spend, time, on, a, too, hot, summer, weekend, si...   \n",
       "1  [probably, my, alltime, favorite, movie, a, story, of, selflessness, sacrifice, and, dedication,...   \n",
       "2  [i, sure, would, like, to, see, a, resurrection, of, a, up, dated, seahunt, series, with, the, t...   \n",
       "3  [this, show, was, an, amazing, fresh, innovative, idea, in, the, 70s, when, it, first, aired, th...   \n",
       "4  [encouraged, by, the, positive, comments, about, this, film, on, here, i, was, looking, forward,...   \n",
       "\n",
       "                                                                                      review_stopwords  \n",
       "0  [thought, wonderful, way, spend, time, hot, summer, weekend, sitting, air, conditioned, theater,...  \n",
       "1  [probably, alltime, favorite, movie, story, selflessness, sacrifice, dedication, noble, cause, p...  \n",
       "2  [sure, would, like, see, resurrection, dated, seahunt, series, tech, today, would, bring, back, ...  \n",
       "3  [show, amazing, fresh, innovative, idea, 70s, first, aired, first, 7, 8, years, brilliant, thing...  \n",
       "4  [encouraged, positive, comments, film, looking, forward, watching, film, bad, mistake, ive, seen...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prelim['review_stopwords'] = imdb_prelim['review_token'].apply(remove_stopwords)\n",
    "imdb_prelim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "def perform_stemming(text):\n",
    "    new_text = [ps.stem(word) for word in text]\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_token</th>\n",
       "      <th>review_stopwords</th>\n",
       "      <th>review_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to, spend, time, on, a, too, hot, summer, weekend, si...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, summer, weekend, sitting, air, conditioned, theater,...</td>\n",
       "      <td>thought wonder way spend time hot summer weekend sit air condit theater watch lightheart comedi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[probably, my, alltime, favorite, movie, a, story, of, selflessness, sacrifice, and, dedication,...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, selflessness, sacrifice, dedication, noble, cause, p...</td>\n",
       "      <td>probabl alltim favorit movi stori selfless sacrific dedic nobl caus preachi bore never get old d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sure would like to see a resurrection of a up dated seahunt series with the tech they have tod...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, sure, would, like, to, see, a, resurrection, of, a, up, dated, seahunt, series, with, the, t...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, seahunt, series, tech, today, would, bring, back, ...</td>\n",
       "      <td>sure would like see resurrect date seahunt seri tech today would bring back kid excit mei grew b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this show was an amazing fresh  innovative idea in the 70s when it first aired the first 7 or 8 ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[this, show, was, an, amazing, fresh, innovative, idea, in, the, 70s, when, it, first, aired, th...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70s, first, aired, first, 7, 8, years, brilliant, thing...</td>\n",
       "      <td>show amaz fresh innov idea 70 first air first 7 8 year brilliant thing drop 1990 show realli fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encouraged by the positive comments about this film on here i was looking forward to watching th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[encouraged, by, the, positive, comments, about, this, film, on, here, i, was, looking, forward,...</td>\n",
       "      <td>[encouraged, positive, comments, film, looking, forward, watching, film, bad, mistake, ive, seen...</td>\n",
       "      <td>encourag posit comment film look forward watch film bad mistak ive seen 950 film truli one worst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                review  \\\n",
       "0  i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air ...   \n",
       "1  probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble c...   \n",
       "2  i sure would like to see a resurrection of a up dated seahunt series with the tech they have tod...   \n",
       "3  this show was an amazing fresh  innovative idea in the 70s when it first aired the first 7 or 8 ...   \n",
       "4  encouraged by the positive comments about this film on here i was looking forward to watching th...   \n",
       "\n",
       "  sentiment  \\\n",
       "0  positive   \n",
       "1  positive   \n",
       "2  positive   \n",
       "3  negative   \n",
       "4  negative   \n",
       "\n",
       "                                                                                          review_token  \\\n",
       "0  [i, thought, this, was, a, wonderful, way, to, spend, time, on, a, too, hot, summer, weekend, si...   \n",
       "1  [probably, my, alltime, favorite, movie, a, story, of, selflessness, sacrifice, and, dedication,...   \n",
       "2  [i, sure, would, like, to, see, a, resurrection, of, a, up, dated, seahunt, series, with, the, t...   \n",
       "3  [this, show, was, an, amazing, fresh, innovative, idea, in, the, 70s, when, it, first, aired, th...   \n",
       "4  [encouraged, by, the, positive, comments, about, this, film, on, here, i, was, looking, forward,...   \n",
       "\n",
       "                                                                                      review_stopwords  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, summer, weekend, sitting, air, conditioned, theater,...   \n",
       "1  [probably, alltime, favorite, movie, story, selflessness, sacrifice, dedication, noble, cause, p...   \n",
       "2  [sure, would, like, see, resurrection, dated, seahunt, series, tech, today, would, bring, back, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70s, first, aired, first, 7, 8, years, brilliant, thing...   \n",
       "4  [encouraged, positive, comments, film, looking, forward, watching, film, bad, mistake, ive, seen...   \n",
       "\n",
       "                                                                                        review_stemmed  \n",
       "0  thought wonder way spend time hot summer weekend sit air condit theater watch lightheart comedi ...  \n",
       "1  probabl alltim favorit movi stori selfless sacrific dedic nobl caus preachi bore never get old d...  \n",
       "2  sure would like see resurrect date seahunt seri tech today would bring back kid excit mei grew b...  \n",
       "3  show amaz fresh innov idea 70 first air first 7 8 year brilliant thing drop 1990 show realli fun...  \n",
       "4  encourag posit comment film look forward watch film bad mistak ive seen 950 film truli one worst...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prelim['review_stemmed'] = imdb_prelim['review_stopwords'].apply(perform_stemming)\n",
    "imdb_prelim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a nobl...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a up dated Seahunt series with the tech they have tod...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative idea in the 70's when it first aired. The first 7 o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this film on here I was looking forward to watching th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                review  \\\n",
       "0  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air...   \n",
       "1  Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a nobl...   \n",
       "2  I sure would like to see a resurrection of a up dated Seahunt series with the tech they have tod...   \n",
       "3  This show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 o...   \n",
       "4  Encouraged by the positive comments about this film on here I was looking forward to watching th...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  negative  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = pd.read_excel(\"IMDB_dataset.xlsx\")\n",
    "imdb.columns = ['review', 'sentiment']\n",
    "imdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature for text message length and % of text that is punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air...</td>\n",
       "      <td>positive</td>\n",
       "      <td>761</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a nobl...</td>\n",
       "      <td>positive</td>\n",
       "      <td>538</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a up dated Seahunt series with the tech they have tod...</td>\n",
       "      <td>positive</td>\n",
       "      <td>577</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative idea in the 70's when it first aired. The first 7 o...</td>\n",
       "      <td>negative</td>\n",
       "      <td>761</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this film on here I was looking forward to watching th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>552</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                review  \\\n",
       "0  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air...   \n",
       "1  Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a nobl...   \n",
       "2  I sure would like to see a resurrection of a up dated Seahunt series with the tech they have tod...   \n",
       "3  This show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 o...   \n",
       "4  Encouraged by the positive comments about this film on here I was looking forward to watching th...   \n",
       "\n",
       "  sentiment  body_len  punct%  \n",
       "0  positive       761   0.053  \n",
       "1  positive       538   0.052  \n",
       "2  positive       577   0.021  \n",
       "3  negative       761   0.043  \n",
       "4  negative       552   0.056  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)\n",
    "\n",
    "imdb['body_len'] = imdb['review'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "imdb['punct%'] = imdb['review'].apply(lambda x: count_punct(x))\n",
    "\n",
    "imdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Punctuations and performing Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5000)\n",
      "['' '0' '1' ... 'zoom' 'â' 'ã']\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "tfidf_vect_sample = TfidfVectorizer(analyzer=clean_text, max_features=5000)\n",
    "X_tfidf_sample = tfidf_vect_sample.fit_transform(imdb['review'])\n",
    "print(X_tfidf_sample.shape)\n",
    "print(tfidf_vect_sample.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>577</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>761</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%    0    1    2         3    4    5    6    7  ...  4990  \\\n",
       "0       761   0.053  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1       538   0.052  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "2       577   0.021  0.0  0.0  0.0  0.108878  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "3       761   0.043  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4       552   0.056  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "   4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 5002 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features = pd.concat([imdb['body_len'], imdb['punct%'], pd.DataFrame(X_tfidf_sample.toarray())], axis=1)\n",
    "X_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizers output sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1010</th>\n",
       "      <th>10br</th>\n",
       "      <th>11</th>\n",
       "      <th>110</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtub</th>\n",
       "      <th>youv</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>â</th>\n",
       "      <th>ã</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1        10  100  1000  1010  10br   11  110  ...  your  \\\n",
       "0      0.0  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  ...   0.0   \n",
       "1      0.0  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  ...   0.0   \n",
       "2      0.0  0.0  0.0  0.108878  0.0   0.0   0.0   0.0  0.0  0.0  ...   0.0   \n",
       "3      0.0  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  ...   0.0   \n",
       "4      0.0  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  ...   0.0   \n",
       "...    ...  ...  ...       ...  ...   ...   ...   ...  ...  ...  ...   ...   \n",
       "24995  0.0  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  ...   0.0   \n",
       "24996  0.0  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  ...   0.0   \n",
       "24997  0.0  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  ...   0.0   \n",
       "24998  0.0  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  ...   0.0   \n",
       "24999  0.0  0.0  0.0  0.000000  0.0   0.0   0.0   0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "       youth  youtub  youv  zero  zombi  zone  zoom    â    ã  \n",
       "0        0.0     0.0   0.0   0.0    0.0   0.0   0.0  0.0  0.0  \n",
       "1        0.0     0.0   0.0   0.0    0.0   0.0   0.0  0.0  0.0  \n",
       "2        0.0     0.0   0.0   0.0    0.0   0.0   0.0  0.0  0.0  \n",
       "3        0.0     0.0   0.0   0.0    0.0   0.0   0.0  0.0  0.0  \n",
       "4        0.0     0.0   0.0   0.0    0.0   0.0   0.0  0.0  0.0  \n",
       "...      ...     ...   ...   ...    ...   ...   ...  ...  ...  \n",
       "24995    0.0     0.0   0.0   0.0    0.0   0.0   0.0  0.0  0.0  \n",
       "24996    0.0     0.0   0.0   0.0    0.0   0.0   0.0  0.0  0.0  \n",
       "24997    0.0     0.0   0.0   0.0    0.0   0.0   0.0  0.0  0.0  \n",
       "24998    0.0     0.0   0.0   0.0    0.0   0.0   0.0  0.0  0.0  \n",
       "24999    0.0     0.0   0.0   0.0    0.0   0.0   0.0  0.0  0.0  \n",
       "\n",
       "[25000 rows x 5000 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_df = pd.DataFrame(X_tfidf_sample.toarray())\n",
    "X_tfidf_df.columns = tfidf_vect_sample.get_feature_names_out()\n",
    "X_tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GridSearchCV on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>190.626401</td>\n",
       "      <td>7.195601</td>\n",
       "      <td>2.252400</td>\n",
       "      <td>0.406578</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 75}</td>\n",
       "      <td>0.8384</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>0.8410</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>0.84292</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>136.205416</td>\n",
       "      <td>6.970463</td>\n",
       "      <td>0.582383</td>\n",
       "      <td>0.156314</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 75}</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.8410</td>\n",
       "      <td>0.8450</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>0.84248</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>199.466200</td>\n",
       "      <td>3.768933</td>\n",
       "      <td>5.223601</td>\n",
       "      <td>2.721443</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 75}</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>0.8408</td>\n",
       "      <td>0.8446</td>\n",
       "      <td>0.84236</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140.238799</td>\n",
       "      <td>5.972223</td>\n",
       "      <td>4.244600</td>\n",
       "      <td>3.047519</td>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 75}</td>\n",
       "      <td>0.8358</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>0.8336</td>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.8396</td>\n",
       "      <td>0.83868</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>127.580800</td>\n",
       "      <td>4.249169</td>\n",
       "      <td>2.017400</td>\n",
       "      <td>0.485326</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 50}</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>0.8470</td>\n",
       "      <td>0.8362</td>\n",
       "      <td>0.8342</td>\n",
       "      <td>0.8394</td>\n",
       "      <td>0.83752</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7      190.626401      7.195601         2.252400        0.406578   \n",
       "15     136.205416      6.970463         0.582383        0.156314   \n",
       "11     199.466200      3.768933         5.223601        2.721443   \n",
       "3      140.238799      5.972223         4.244600        3.047519   \n",
       "6      127.580800      4.249169         2.017400        0.485326   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "7               60                 75   \n",
       "15            None                 75   \n",
       "11              90                 75   \n",
       "3               30                 75   \n",
       "6               60                 50   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "7     {'max_depth': 60, 'n_estimators': 75}             0.8384   \n",
       "15  {'max_depth': None, 'n_estimators': 75}             0.8328   \n",
       "11    {'max_depth': 90, 'n_estimators': 75}             0.8380   \n",
       "3     {'max_depth': 30, 'n_estimators': 75}             0.8358   \n",
       "6     {'max_depth': 60, 'n_estimators': 50}             0.8308   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7              0.8518             0.8410             0.8420   \n",
       "15             0.8566             0.8410             0.8450   \n",
       "11             0.8510             0.8374             0.8408   \n",
       "3              0.8456             0.8336             0.8388   \n",
       "6              0.8470             0.8362             0.8342   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7              0.8414          0.84292        0.004607                1  \n",
       "15             0.8370          0.84248        0.008144                2  \n",
       "11             0.8446          0.84236        0.005014                3  \n",
       "3              0.8396          0.83868        0.004071                4  \n",
       "6              0.8394          0.83752        0.005501                5  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 25, 50, 75],\n",
    "        'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_tfidf_df, imdb['sentiment'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GridSearchCV on Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>395.187996</td>\n",
       "      <td>10.132773</td>\n",
       "      <td>0.223406</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 7}</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7574</td>\n",
       "      <td>0.7438</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.75252</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>361.163016</td>\n",
       "      <td>33.930021</td>\n",
       "      <td>0.504998</td>\n",
       "      <td>0.143876</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}</td>\n",
       "      <td>0.7488</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.7508</td>\n",
       "      <td>0.7454</td>\n",
       "      <td>0.74752</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>508.958348</td>\n",
       "      <td>13.756940</td>\n",
       "      <td>2.760804</td>\n",
       "      <td>3.090839</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 7}</td>\n",
       "      <td>0.7302</td>\n",
       "      <td>0.7546</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.74240</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>263.642550</td>\n",
       "      <td>3.963824</td>\n",
       "      <td>1.730794</td>\n",
       "      <td>1.591923</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 3}</td>\n",
       "      <td>0.7346</td>\n",
       "      <td>0.7432</td>\n",
       "      <td>0.7374</td>\n",
       "      <td>0.7474</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.74124</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>357.244804</td>\n",
       "      <td>8.617922</td>\n",
       "      <td>1.143995</td>\n",
       "      <td>0.086308</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}</td>\n",
       "      <td>0.7272</td>\n",
       "      <td>0.7408</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.7274</td>\n",
       "      <td>0.7284</td>\n",
       "      <td>0.73088</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11     395.187996     10.132773         0.223406        0.086645   \n",
       "10     361.163016     33.930021         0.504998        0.143876   \n",
       "7      508.958348     13.756940         2.760804        3.090839   \n",
       "9      263.642550      3.963824         1.730794        1.591923   \n",
       "6      357.244804      8.617922         1.143995        0.086308   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "11                 0.1               9                  7   \n",
       "10                 0.1               9                  5   \n",
       "7                  0.1               7                  7   \n",
       "9                  0.1               9                  3   \n",
       "6                  0.1               7                  5   \n",
       "\n",
       "                                                       params  \\\n",
       "11  {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 7}   \n",
       "10  {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}   \n",
       "7   {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 7}   \n",
       "9   {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 3}   \n",
       "6   {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "11             0.7500             0.7574             0.7438   \n",
       "10             0.7488             0.7516             0.7410   \n",
       "7              0.7302             0.7546             0.7388   \n",
       "9              0.7346             0.7432             0.7374   \n",
       "6              0.7272             0.7408             0.7306   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "11             0.7600             0.7514          0.75252        0.005717   \n",
       "10             0.7508             0.7454          0.74752        0.003900   \n",
       "7              0.7420             0.7464          0.74240        0.008085   \n",
       "9              0.7474             0.7436          0.74124        0.004609   \n",
       "6              0.7274             0.7284          0.73088        0.005105   \n",
       "\n",
       "    rank_test_score  \n",
       "11                1  \n",
       "10                2  \n",
       "7                 3  \n",
       "9                 4  \n",
       "6                 5  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [1,3,5,7],\n",
    "    'max_depth': [5,7,9],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(gb, param, cv=5, n_jobs=-1)\n",
    "gs2_fit = gs2.fit(X_tfidf_df, imdb['sentiment'])\n",
    "pd.DataFrame(gs2_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Evaluation Metrics:\n",
      "Best Parameters: {'max_depth': 60, 'n_estimators': 75}\n",
      "Accuracy: 0.9974\n",
      "Precision: 0.9948269001193792\n",
      "Recall: 1.0\n",
      "F1 Score: 0.997406742469579\n"
     ]
    }
   ],
   "source": [
    "# Best parameters for Random Forest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "best_rf_params = gs_fit.best_params_\n",
    "\n",
    "# Create and fit the Random Forest model with the best parameters\n",
    "best_rf_model = RandomForestClassifier(**best_rf_params)\n",
    "best_rf_model.fit(X_tfidf_df, imdb['sentiment'])\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_predictions = best_rf_model.predict(X_tfidf_df)  \n",
    "rf_accuracy = accuracy_score(imdb['sentiment'], rf_predictions)\n",
    "rf_precision = precision_score(imdb['sentiment'], rf_predictions, pos_label='positive')\n",
    "rf_recall = recall_score(imdb['sentiment'], rf_predictions, pos_label='positive')\n",
    "rf_f1 = f1_score(imdb['sentiment'], rf_predictions, pos_label='positive')\n",
    "\n",
    "print(\"Random Forest Evaluation Metrics:\")\n",
    "print(f\"Best Parameters: {best_rf_params}\")\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "print(f\"Precision: {rf_precision}\")\n",
    "print(f\"Recall: {rf_recall}\")\n",
    "print(f\"F1 Score: {rf_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Evaluation Metrics:\n",
      "Accuracy: 0.79588\n",
      "Precision: 0.7420009160505137\n",
      "Recall: 0.9072\n",
      "F1 Score: 0.8163265306122449\n"
     ]
    }
   ],
   "source": [
    "# Best parameters for Gradient Boosting\n",
    "best_gb_params = gs2_fit.best_params_\n",
    "\n",
    "# Create and fit the Gradient Boosting model with the best parameters\n",
    "best_gb_model = GradientBoostingClassifier(**best_gb_params)\n",
    "best_gb_model.fit(X_tfidf_df, imdb['sentiment'])\n",
    "\n",
    "# Evaluate the Gradient Boosting model\n",
    "gb_predictions = best_gb_model.predict(X_tfidf_df)  # You might want to use a separate test set for evaluation\n",
    "gb_accuracy = accuracy_score(imdb['sentiment'], gb_predictions)\n",
    "gb_precision = precision_score(imdb['sentiment'], gb_predictions, pos_label='positive')\n",
    "gb_recall = recall_score(imdb['sentiment'], gb_predictions, pos_label='positive')\n",
    "gb_f1 = f1_score(imdb['sentiment'], gb_predictions, pos_label='positive')\n",
    "\n",
    "print(\"\\nGradient Boosting Evaluation Metrics:\")\n",
    "print(f\"Best Parameters: {best_gb_params}\")\n",
    "print(f\"Accuracy: {gb_accuracy}\")\n",
    "print(f\"Precision: {gb_precision}\")\n",
    "print(f\"Recall: {gb_recall}\")\n",
    "print(f\"F1 Score: {gb_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
